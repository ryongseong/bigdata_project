{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracts = re.compile('[^ 가-힣|a-z|A-Z|0-9|\\[|\\]|(|)|-|~|?|!|.|,|:|;|%]+')\n",
    "cost_extracts = re.compile('[^ 가-힣|a-z|A-Z|\\[|\\]|(|)|-|~|?|!|.|,|:|;|%]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서울\n",
    "# data_url = open('./data/goodchoice_seoul.csv', 'w', encoding='utf8') # url 저장 관련 csv파일\n",
    "# data = open('./data/info_seoul.csv', 'w', encoding='utf8') # 정보 저장관련 csv 파일\n",
    "\n",
    "# 부산\n",
    "data_url = open('./data/goodchoice_busan.csv', 'w', encoding='utf8') # url 저장 관련 csv파일\n",
    "data = open('./data/info_busan.csv', 'w', encoding='utf8') # 정보 저장관련 csv 파일\n",
    "data_r = open('./data/reviews_busan.csv', 'w', encoding='utf8') # 리뷰 저장관련 csv 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window() #전체 화면\n",
    "# Url = 'https://www.goodchoice.kr/product/search/1/7052' #서울 역삼, 강남, 논현\n",
    "Url = 'https://www.goodchoice.kr/product/search/1/7044' #부산 광안리, 수영, 민락\n",
    "driver.get(Url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = driver.find_element(By.ID, \"poduct_list_area\")\n",
    "urlList = urls.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "for li in urlList:\n",
    "    aTag = li.find_element(By.TAG_NAME, 'a')\n",
    "    href = aTag.get_attribute('href')\n",
    "    data_url.write(href)\n",
    "    data_url.write('\\n')\n",
    "\n",
    "data_url.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.write('\"name\"')\n",
    "data.write(', ')\n",
    "data.write('\"basic_info\"')\n",
    "data.write(', ')\n",
    "data.write('\"cost_info\"')\n",
    "data.write(', ')\n",
    "data.write('\"avg_stars\"')\n",
    "data.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_r.write('\"stars\"')\n",
    "data_r.write(', ')\n",
    "data_r.write('\"review\"')\n",
    "data_r.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서울\n",
    "# f = open('C:/Users/xmssn/OneDrive/바탕 화면/대학/3학년1학기/빅데이터시스템/project/python_01/data/goodchoice_seoul.csv', 'r', encoding='utf8')\n",
    "\n",
    "# 부산\n",
    "f = open('C:/Users/xmssn/OneDrive/바탕 화면/대학/3학년1학기/빅데이터시스템/project/python_01/data/goodchoice_busan.csv', 'r', encoding='utf8')\n",
    "rdr = csv.reader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 정보, 요금 정보 및 평점\n",
    "for line in rdr:\n",
    "    addr = line[0]\n",
    "    rs = requests.get(addr)\n",
    "    rs.encoding = None\n",
    "    html = rs.text\n",
    "    soup = bs(html, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        tarname = soup.select('#content > div.top > div.right')\n",
    "        rname = soup.find(\"div\", {\"class\" : \"info\"})\n",
    "        name = rname.find(\"h2\")\n",
    "        name = name.text\n",
    "\n",
    "        tarbasic_info = soup.select('#content > article.detail_info > section.default_info')\n",
    "        basic_info = ''\n",
    "        for text in tarbasic_info:\n",
    "            basic_info += text.getText()\n",
    "\n",
    "        basic_info = extracts.sub('', basic_info)\n",
    "        basic_info = re.sub(' +', ' ', basic_info)\n",
    "        basic_info = '\"'+basic_info+'\"'\n",
    "\n",
    "\n",
    "        tarcost_info = soup.select('#content > article.detail_info.on > section.table_wrap > div:nth-child(2) > table:nth-child(2)')\n",
    "        rcost_info = soup.find(\"table\", {\"class\" : \"table_type_02\"})\n",
    "        cost_info = rcost_info.find(\"span\")\n",
    "        cost_info = cost_info.text\n",
    "\n",
    "\n",
    "        tarstar_info = soup.select('#content > div.top > div.right > div.info')\n",
    "        rstar_info = soup.find(\"div\", {\"class\" : \"score_cnt\"})\n",
    "        avg_star_info = rstar_info.find(\"span\").text[0:4]\n",
    "\n",
    "        data.write(name)\n",
    "        data.write(', ')\n",
    "        data.write(basic_info)\n",
    "        data.write(', ')\n",
    "        data.write(cost_info)\n",
    "        data.write(', ')\n",
    "        data.write(avg_star_info)\n",
    "        data.write('\\n')\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for line in rdr:\n",
    "#     addr = line[0]\n",
    "#     rs = requests.get(addr)\n",
    "#     rs.encoding = None\n",
    "#     html2 = rs.text\n",
    "#     soup2 = bs(html2, 'html.parser')\n",
    "\n",
    "#     try:\n",
    "#         tarstar = soup2.select('#review > ul > li:nth-child(1) > div')\n",
    "#         rstar = soup2.find(\"div\", {\"class\" : \"score_wrap_sm\"})\n",
    "#         star = rstar.find(\"num\").text[0:4]\n",
    "\n",
    "#         data_r.write(star)\n",
    "#         data_r.write('\\n')\n",
    "#     except:\n",
    "#         break\n",
    "\n",
    "# f.close()\n",
    "# data_r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for page in range(1, 5):\n",
    "#     review_addr = addr+\"#{}\".format(page)\n",
    "#     html2 = requests.get(review_addr)\n",
    "#     html2.encoding = None\n",
    "#     html2 = html2.text\n",
    "#     soup2 = bs(html2, 'html.parser')\n",
    "\n",
    "#     for i in range(1, 11):\n",
    "#         tarstar = soup2.select(\"#review > ul > li:nth-child({}) > div\".format(i))\n",
    "#         rstar = soup2.find(\"div\", {\"class\" : \"score_wrap_sm\"})\n",
    "#         star = rstar.find(\"div\", {\"class\":\"num\"}).text[0:4]\n",
    "#         data_r.write(star)\n",
    "#         data_r.write('\\n')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# f.close()\n",
    "# data_r.close()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
